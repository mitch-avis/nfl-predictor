"""
Utility functions for data handling and logging in the nfl_predictor project.

This module provides utility functions to read from and write data to CSV files, manage data
refreshes, and facilitate logging throughout the nfl_predictor project.

It leverages pandas for data manipulation and custom logging for debug and information purposes.
The module ensures efficient data access and manipulation, supporting the project's data processing
needs.
"""

import os
import sys
from typing import Callable

import pandas as pd
from numpy import ndarray

from nfl_predictor import constants
from nfl_predictor.utils.logger import log

DATA_PATH = constants.DATA_PATH


def read_write_data(
    data_name: str, func: Callable, *args, force_refresh: bool = False, **kwargs
) -> pd.DataFrame:
    """
    Reads data from a CSV file or generates it using a specified function, then writes it back to a
    CSV.

    This function checks if a CSV file with the specified data name exists.  If it does and
    `force_refresh` is False, it reads the data from the CSV file into a DataFrame.  If the file
    does not exist or `force_refresh` is True, it calls the provided function with the given
    arguments to generate the data, writes the data to a CSV file, and returns the DataFrame.

    Args:
        data_name (str):                The name of the data file (without extension) to read from
                                        or write to.
        func (Callable):                The function to call to generate the data if the CSV does
                                        not exist or a refresh is forced.
        *args:                          Variable length argument list to pass to the function.
        force_refresh (bool, optional): Whether to force refreshing the data by calling the function
                                        even if the CSV exists. Defaults to False.
        **kwargs:                       Arbitrary keyword arguments to pass to the function.

    Returns:
        pd.DataFrame:   The DataFrame containing the data read from the CSV or generated by the
                        function.
    """
    # Initialize an empty DataFrame
    dataframe = pd.DataFrame()
    file_path = f"{DATA_PATH}/{data_name}.csv"

    # Check if the CSV file exists and read it if force_refresh is not True
    if os.path.isfile(file_path) and not force_refresh:
        dataframe = read_df_from_csv(file_path, check_exists=False)

    # If the DataFrame is empty (file doesn't exist) or force_refresh is True, generate the data
    if dataframe.empty or force_refresh:
        log.debug("* Calling %s()", func.__name__)
        dataframe = pd.DataFrame(func(*args, **kwargs))
        # Write the generated DataFrame to a CSV file
        write_df_to_csv(dataframe, file_path)

    return dataframe


def read_df_from_csv(file_path: str, check_exists: bool = True) -> pd.DataFrame:
    """
    Reads a DataFrame from a CSV file, optionally checking if the file exists first.

    This function reads a CSV file into a pandas DataFrame.  If `check_exists` is True, it first
    checks if the file exists at the specified path.  If the file does not exist, it logs an
    informational message and terminates the program.  The CSV file is read using pandas, with the
    first column set as the index.

    Args:
        file_path (str):                The full path of the CSV file to read.
        check_exists (bool, optional):  Whether to check if the file exists before reading. Defaults
                                        to True.

    Returns:
        pd.DataFrame:   The DataFrame loaded from the CSV file.

    Raises:
        SystemExit: If `check_exists` is True and the CSV file does not exist.
    """
    # Check if the file exists, if required
    if check_exists and not os.path.isfile(file_path):
        # Log an error message and exit if the file does not exist
        log.info("%s not found!", os.path.basename(file_path))
        sys.exit(1)

    # Read the CSV file into a DataFrame, using the first column as the index
    dataframe = pd.read_csv(file_path, index_col=0)
    return dataframe


def write_df_to_csv(dataframe: pd.DataFrame, file_path: str) -> None:
    """
    Writes a DataFrame to a CSV file, ensuring the directory exists.

    This function checks if the directory for the specified CSV file exists within a predefined data
    path (`DATA_PATH`).  If the directory does not exist, it is created.  Then, the DataFrame is
    written to the CSV file at the specified path, including the DataFrame's index.

    Args:
        dataframe (pd.DataFrame):   The DataFrame to be written to a CSV file.
        file_path (str):            The full path of the target CSV file.

    Returns:
        None
    """
    # Construct the directory path for the CSV file
    directory_path = os.path.dirname(file_path)

    # Create the directory if it does not exist
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)

    # Write the DataFrame to the CSV file, including the index
    dataframe.to_csv(file_path, index=True)


def display_predictions(y_pred: ndarray, x_test: pd.DataFrame) -> None:
    """
    Displays the predicted probabilities of match outcomes.

    For each prediction in `y_pred`, this function calculates and logs the probability of the away
    team winning and the home team winning.  It extracts the week, away team name, and home team
    name from `x_test` for each prediction to format a display string that includes all relevant
    information.

    Args:
        y_pred (ndarray):       An array of predicted probabilities for the away team winning.
        x_test (pd.DataFrame):  The test dataset containing the 'week', 'away_name', and 'home_name'
                                columns for each game.

    Returns:
        None
    """
    # Reset the index of x_test once to avoid repeated operations
    x_test_reset = x_test.reset_index().drop(columns="index")

    for idx, game in enumerate(y_pred):
        # Calculate probabilities
        away_win_prob = round(game * 100, 2)
        home_win_prob = round((1 - game) * 100, 2)

        # Extract game details
        week = x_test_reset.loc[idx, "week"]
        away_team = x_test_reset.loc[idx, "away_name"]
        home_team = x_test_reset.loc[idx, "home_name"]

        # Format and log the display string
        display_string = (
            f"{'Week ' + str(week):<7}: "
            f"{away_team:<21} ({str(away_win_prob) + '%)':<8} at "
            f"{home_team:<21} ({str(home_win_prob) + '%)':<8}"
        )
        log.info(display_string)


def flatten_dict(nested_dict):
    """
    Flattens a nested dictionary into a dictionary with tuple keys.

    This function recursively flattens a nested dictionary.  Each key in the resulting dictionary
    is a tuple representing the path to the corresponding value in the nested dictionary.  For
    example, the value at nested_dict['a']['b']['c'] would be represented in the flattened
    dictionary with the key ('a', 'b', 'c').

    Args:
        nested_dict (dict): The nested dictionary to flatten.

    Returns:
        dict:   A flattened dictionary where keys are tuples representing paths in the nested
                dictionary.
    """
    res = {}
    # Check if the input is a dictionary
    if isinstance(nested_dict, dict):
        # Iterate through each item in the dictionary
        for k, v in nested_dict.items():
            # Recursively flatten the dictionary
            flattened_dict = flatten_dict(v)
            for key, val in flattened_dict.items():
                # Prepend the current key to the tuple key from the nested dictionary
                res[(k,) + key] = val
    else:
        # Base case: if it's not a dictionary, return it wrapped in a tuple
        res[()] = nested_dict
    return res


def nested_dict_to_df(values_dict):
    """
    Converts a nested dictionary into a pandas DataFrame with multi-level indexing.

    This function first flattens the nested dictionary, where each key in the resulting flat
    dictionary is a tuple representing the path to the corresponding value in the nested
    dictionary.  It then converts this flat dictionary into a DataFrame.  The DataFrame is
    restructured to have multi-level indexing for rows, and columns are unstacked based on the
    last level of the tuple keys.  Finally, the column names are formatted to only include the
    names from the last level of the tuple keys.

    Args:
        values_dict (dict): The nested dictionary to convert.

    Returns:
        pd.DataFrame:   A DataFrame representation of the nested dictionary, with multi-level
                        indexing for rows and formatted column names.
    """
    # Flatten the nested dictionary
    flat_dict = flatten_dict(values_dict)
    # Convert the flat dictionary to a DataFrame
    df = pd.DataFrame.from_dict(flat_dict, orient="index")
    # Convert the index to a MultiIndex
    df.index = pd.MultiIndex.from_tuples(df.index)
    # Unstack the DataFrame based on the last level of the tuple keys
    df = df.unstack(level=-1)
    # Format the column names to only include the last level of the tuple keys
    df.columns = df.columns.map(lambda x: f"{x[1]}")
    return df
